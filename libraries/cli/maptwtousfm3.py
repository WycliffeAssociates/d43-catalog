#!/usr/bin/env python2
# -*- coding: utf-8 -*-

"""
This tool reads USFM files generated by csvtousfm3.py
and injects tW links into the matching Greek or Hebrew words.

Errors are recorded in errors.log in the output directory.

Assumptions:
1. The tW RC contains a list of occurrences for each word.
2. This list of occurrences is stored in the config.yaml file.
3. The word content contains a #2 heading titled "Word Data" under which are strong's numbers.
"""

import argparse
import os
import sys
import re
import logging

from resource_container import factory, ResourceContainer
from libraries.tools.file_utils import write_file, read_file
from libraries.tools.str_utils import unzpad
from libraries.tools.usfm_utils import USFMWordReader, tWPhrase

LOGGER_NAME='map_tw_to_usfm'

def indexWordsLocation(words_rc):
    """
    Generates an index of word occurrences where words may be looked up by
    textual occurrence.
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :return: a dictionary of words keyed by location
    """
    logger = logging.getLogger(LOGGER_NAME)
    config = words_rc.config()
    location_categories = ['occurrences', 'false_positives']
    index = {name:{} for name in location_categories}
    for word in config:
        word_obj = config[word]
        for location_category in word_obj:
            if location_category in location_categories:
                locations = word_obj[location_category]
                for location in locations:
                    try:
                        parts = location.split('/')
                        length = len(parts)
                        verse = unzpad(parts[length-1])
                        chapter = unzpad(parts[length-2])
                        book = parts[length - 3]
                        path = '{}/{}/{}'.format(book, chapter, verse)
                        if path in index[location_category]:
                            # append to index
                            index[location_category][path].append(word)
                        else:
                            # create index
                            index[location_category][path] = [word]
                    except Exception as e:
                        logger.error('Failed to parse location: {}'.format(location))
                        raise e
    return index

def findStrongs(word, words_rc):
    """
    Retrieves the strong numbers for a word from it's data file
    :param word: the word to index
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :return: a list of strongs
    """

    # TRICKY: the config.yaml does not provide sufficient information to
    # locate the word, however we only have 3 options.
    # There should not be any duplicates within these folders.
    logger = logging.getLogger(LOGGER_NAME)

    numbers = []
    data = words_rc.read_chunk('kt', word)
    if not data:
        data = words_rc.read_chunk('names', word)
    if not data:
        data = words_rc.read_chunk('other', word)
    if not data:
        # TRICKY: ignore missing words. The config.yaml file was inaccurate
        return numbers

    try:
        numbers = parseStrongs(data)
    except Exception as e:
        category = _getWordCategory(word, words_rc)
        logger.error('{} in word "{}/{}"'.format(e, category, word))

    return numbers

def parseStrongs(word_data):
    """
    Parses the strong's numbers from word data
    :param word_data:
    :return:
    """
    header = re.findall('^#+\s*Word\s+Data\s*\:?.*', word_data, re.MULTILINE | re.IGNORECASE)
    if header:
        word_data = word_data.split(header[0])[1]
        return re.findall('[HG]\d+', word_data, re.MULTILINE | re.IGNORECASE)
    else:
        raise Exception('Missing Word Data section')

def _getWordCategory(word, words_rc):
    """
    Retrieves the category of a word
    :param word:
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :return:
    """
    # TRICKY: the config.yaml does not provide enough information for us to backtrack words.
    # however, we know there are only 3 locations
    categories = ['kt', 'names', 'other']
    for cat in categories:
        if '{}.md'.format(word) in words_rc.chunks(cat):
            return cat
    return None

def _makeWordLink(word, words_rc):
    """
    Generates a language agnostic link to a tW
    :param word:
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :return: a new rc link
    """
    category = _getWordCategory(word, words_rc)
    if not category:
        raise Exception('Failed to look up category for word {}'.format(word))

    return 'rc://*/tw/dict/bible/{}/{}'.format(category, word)

def _getLocationWords(location, words_index):
    """
    Retrieves the words found at the passage location
    :param location: The passage location e.g. book/chapter/verse without z-padding
    :param words_index:
    :return: a list of words
    """
    if location in words_index:
        return words_index[location]
    else:
        return []

def _getWords(strongs, words_strongs_index):
    """
    Returns a list of words that match the strong's number.
    :param strongs:
    :param words_strongs_index:
    :param words_false_positives_index:
    :return:
    """
    if strongs in words_strongs_index:
        return words_strongs_index[strongs]
    else:
        return []

def indexWordByStrongs(words_rc):
    """
    Generates an index of words keyed by strong numbers
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :return: a dictionary of words keyed by strong's
    """
    logger = logging.getLogger(LOGGER_NAME)
    index = {}
    for category in words_rc.chapters():
        for word in words_rc.chunks(category):
            if not word.endswith('.md'):
                # TRICKY: exclude erroneous files such as .DS_Store
                continue
            word = os.path.splitext(word)[0]
            data = words_rc.read_chunk(category, word)
            numbers = []
            try:
                numbers = parseStrongs(data)
            except Exception as e:
                logger.error('{} in word "{}/{}"'.format(e, category, word))
            for num in numbers:
                # TRICKY: strongs are 6 characters long
                strong = normalizeStrongPadding(num, '000000').upper()
                if strong in index:
                    # append word to strong
                    index[strong].append(word)
                else:
                    # create index
                    index[strong] = [word]
    return index

def indexLocationStrongs(location, words_index, words_rc, strongs_index=None):
    """
    Generates an index of strong numbers associated with words found in the given location.
    If the existing index is provided this may not hit the filesystem.
    :param location:
    :param words_index:
    :param words_rc:
    :param strongs_index: the existing index. This will be updated if set
    :return: a dictionary of strong numbers keyed by word
    """
    words = _getLocationWords(location, words_index)
    if strongs_index:
        index = strongs_index
    else:
        index = {}

    for word in words:
        if word not in index:
            index[word] = findStrongs(word, words_rc)
    return index

def getStrongs(word, strongs_index):
    """
    Retrieves the strongs found for a word
    :param word:
    :param strongs_index:
    :return: a list of strong numbers
    """
    if word in strongs_index:
        return strongs_index[word]
    else:
        return []

def getStrongWords(strong_number, available_words, strongs_index):
    """
    Returns words that are mapped to the strong's number
    :param strong_number:
    :param words: a list of words available for mapping. These are available based on the passage location.
    :param strongs_index: an index of strong's numbers from which to read
    :return:
    """
    words = []
    for word in available_words:
        strongs = getStrongs(word, strongs_index)
        for strong in strongs:
            # TRICKY: reverse zero pad numbers from the index to match the length
            formatted_strong = normalizeStrongPadding(strong, strong_number)
            if formatted_strong.lower() == strong_number.lower():
                words.append(word)
    return words

def normalizeStrongPadding(strong, strong_template):
    """
    Normalizes the padding on a strong number so it matches the template
    :param strong:
    :param strong_template:
    :return:
    """
    return (strong + '000000')[:len(strong_template)]

def mapUSFMByGlobalSearch(usfm, words_rc, words_strongs_index, words_false_positives_index):
    """
    Injects tW links into un-matched usfm words as matches are found in the global index.
    :param usfm:
    :param words_rc:
    :param words_strongs_index:
    :param words_false_positives_index:
    :return:
    """
    logger = logging.getLogger(LOGGER_NAME)
    reader = USFMWordReader(usfm)
    for line, strong, index in reader:
        if re.match(r'.*x-tw=', line):
            # skip lines already mapped
            continue

        book, chapter, verse = reader.location()
        location = '{}/{}/{}'.format(book, chapter, verse)
        words = _getWords(strong, words_strongs_index)
        # exclude words marked as false positives
        false_positives = _getLocationWords(location, words_false_positives_index)
        filtered = [w for w in words if not w in false_positives]
        if filtered:
            if len(filtered) == 1:
                # inject link at end
                link = 'x-tw="{}"'.format(_makeWordLink(filtered[0], words_rc))
                reader.amendLine(line.replace('\w*', ' ' + link + ' \w*'))
            else:
                links = []
                for word in filtered:
                    links.append(_makeWordLink(word, words_rc).split('bible/')[1])
                logger.warning('Multiple matches found at {} {}:{} {} --- {}'.format(book, chapter, verse, line, '; '.join(links)))
        elif words:
            print('Skipped false positives')
        else:
            logger.warning(u'No matches found for {} {}:{} {}'.format(book, chapter, verse, line))
    return unicode(reader)

# TRICKY: we purposely make strongs_index a mutable parameter
# this allows us to maintain the strong's index.
def mapUSFMByOccurrence(usfm, words_rc, words_index, strongs_index={}):
    """
    Injects tW links into the usfm as matches are found in the list of occurrences.
    :param usfm:
    :type usfm: basestring
    :param words_rc:
    :type words_rc: ResourceContainer.RC
    :param words_index: the index of words keyed by location.
    :param strongs_index: the index of word strong numbers.
    :return: the newly mapped usfm
    """
    logger = logging.getLogger(LOGGER_NAME)

    reader = USFMWordReader(usfm)
    for line, strong, index in reader:
        book, chapter, verse = reader.location()
        location = '{}/{}/{}'.format(book, chapter, verse)
        location_words = _getLocationWords(location, words_index)
        strongs_index = indexLocationStrongs(location, words_index, words_rc, strongs_index)
        words = getStrongWords(strong, location_words, strongs_index)
        if words:
            # inject link at end
            if len(words) > 1:
                logger.info(u'Injecting multiple words at {} {}:{} {}'.format(book, chapter, verse, line))
            for word in words:
                link = 'x-tw="{}"'.format(_makeWordLink(word, words_rc))
                line = line.replace('\w*', ' ' + link + ' \w*')
            reader.amendLine(line)
        elif location_words:
            pass
            # logger.warning('No match found for {} at {}'.format(strong, location))
    return unicode(reader)

def mapPhrases(usfm):
    """
    Converts phrases to usfm milestones.
    :param usfm:
    :return:
    """
    logger = logging.getLogger(LOGGER_NAME)
    reader = USFMWordReader(usfm)
    phrase = None
    lastVerse = None
    lastStrong = None
    for line, strong, index in reader:
        book, chapter, verse = reader.location()
        # init
        if not phrase:
            phrase = tWPhrase(index)

        # TRICKY: break phrases that span multiple verse or duplicate words
        if lastVerse != verse or lastStrong == strong:
            phrase = tWPhrase(index)

        lastVerse = verse
        lastStrong = strong

        if phrase.isLineValid(line):
            phrase.addLine(line)
            continue
        elif phrase.isComplete():
            print('Found phrase at {} {}:{} {} on line {}'.format(book, chapter, verse, phrase.links()[0], index))
            reader.amendPhrase(phrase)

        phrase = None

    return unicode(reader)

def mapDir(usfm_dir, words_rc, output_dir, global_search=False, map_phrases=True):
    """
    Maps tW to words within each USFM file found in the directory.
    :param usfm_dir: a directory containing USFM files generated by `csvtousfm3`
    :param words_rc: the tW resource container
    :type words_rc: ResourceContainer.RC
    :param output_dir: a directory where the newly mapped usfm will be saved
    :param global_search: performs a global word-by-word search in addition to the searcy by occurrence
    :return:
    """
    usfm_files = []
    strongs_index = {}
    for root, dirs, files in os.walk(usfm_dir):
        usfm_files.extend(files)
        break

    print('Generating occurrences index')
    location_index = indexWordsLocation(words_rc)
    if map_phrases:
        print('Phrase mapping enabled.')
    if global_search:
        print('Global search enabled.')
        print('Generating strongs index.')
        strongs_index = indexWordByStrongs(words_rc)

    for file_name in usfm_files:
        if not file_name.endswith('.usfm'):
            continue

        file = os.path.join(usfm_dir, file_name)
        print('{}'.format(file_name))
        usfm = read_file(file)
        usfm = mapUSFMByOccurrence(usfm, words_rc, location_index['occurrences'])
        if map_phrases:
            usfm = mapPhrases(usfm)
        if global_search:
            usfm = mapUSFMByGlobalSearch(usfm, words_rc, strongs_index, location_index['false_positives'])
            # NOTE: if we need to add phrase mapping to global search un-comment these lines
            # if map_phrases:
            #     usfm = mapPhrases(usfm)
        outfile = os.path.join(output_dir, os.path.basename(file))
        write_file(outfile, usfm)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__,
                                   formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('-u', '--usfm', dest='usfm', required=True,
                        help='Directory containing USFM files to read')
    parser.add_argument('-w', '--words', dest='words', required=True,
                        help='tW resource container to read. You can download one from https://git.door43.org/Door43/en_tw')
    parser.add_argument('-o', '--output', dest='output', required=True,
                        help='Director to which the updated USFM will be saved')
    parser.add_argument('-g', '--global', dest='global_search', required=False,
                        default=False,
                        help='Performs a global word-by-word search in addition to the standard search by occurrences.')
    parser.add_argument('-p', '--phrase', dest='map_phrases', required=False,
                        default='True',
                        help='Groups phrases into USFM milestones.')

    args = parser.parse_args(sys.argv[1:])
    if os.path.isfile(args.output):
        raise Exception('Output must be a directory')

    rc = factory.load(args.words)

    errors_log_file = os.path.join(args.output, 'errors.log')
    if os.path.isfile(errors_log_file):
        os.remove(errors_log_file)

    # configure logger
    logger = logging.getLogger(LOGGER_NAME)
    logger.setLevel(logging.WARNING)
    handler = logging.FileHandler(errors_log_file)
    handler.setLevel(logging.WARNING)
    formatter = logging.Formatter("[%(levelname)s] %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    # start
    mapDir(args.usfm, rc, args.output, args.global_search, args.map_phrases.lower() == 'true')

    # announce errors or clean up log file
    if os.path.isfile(errors_log_file):
        statinfo = os.stat(errors_log_file)
        if statinfo.st_size > 0:
            print('WARNING: errors were detected. See {} for details'.format(errors_log_file))
        else:
            os.remove(errors_log_file)

    print('Finished')

